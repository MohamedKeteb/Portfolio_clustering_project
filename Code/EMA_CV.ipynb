{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import process\n",
    "import numpy as np \n",
    "# Jerome path : r'C:\\Users\\33640\\OneDrive\\Documents\\GitHub\\Portfolio_clustering_project\\Data\\DataBase.csv'\n",
    "# Nail path : '/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DataBase.csv'\n",
    "df = pd.read_csv(r'/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DataBase.csv')\n",
    "\n",
    "df.set_index('ticker', inplace=True)\n",
    "\n",
    "df.columns = pd.to_datetime(df.columns.str[1:], format='%Y%m%d').strftime('%d/%m/%Y')\n",
    "\n",
    "df_cleaned = df.fillna(0) # Utilisez la méthode fillna(0) pour remplacer les NaN par 0\n",
    "\n",
    "df_cleaned = df_cleaned.transpose() ## WE WANT COLUMNS TO BE VECTOR OF RETURN FOR A GIVEN TICKER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We denote by $\\bm{X}$ the $d \\times n$ matrix of observations \\textit{i.e.}\n",
    "\n",
    "$$\n",
    "\\bm{X} = \n",
    "\\begin{bmatrix}\n",
    "    r_{1}^{(1)} & r_{1}^{(2)} & \\ldots & r_{1}^{(n)} \\\\\n",
    "    r_{2}^{(1)} & r_{2}^{(2)} & \\ldots & r_{2}^{(n)} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    r_{d}^{(1)} & r_{d}^{(2)} & \\ldots & r_{d}^{(n)} \\\\\n",
    "\\end{bmatrix} \n",
    "= \\begin{bmatrix} \\mathbf{r}^{(1)} | ... |\\mathbf{r}^{(n)}\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{d\\times n}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $d$ corresponds to the number of days\n",
    "- $n$ corresponds to the number of stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, a standard sample covariance can be generalized to include some arbitrary weight profile assigned along the time dimension. In particular, it is expressed in the following form\n",
    "\n",
    "\\begin{equation}\n",
    "\\bm{S_W} := \\frac{1}{d} \\bm{X}'W\\bm{X} \\in \\mathbb{R}^{n\\times n}\n",
    "\\end{equation}\\\\\n",
    "\n",
    "The EWA-SC as defined can be written as a weighted sample covariance matrix if we define the matrix of weighted $W$ to be: \n",
    "\n",
    "\\begin{align*}\n",
    "    W_{t,k} =\n",
    "    \\begin{cases}\n",
    "        d\\frac{1 - \\beta}{1-\\beta^d} \\beta^{d-t} & \\text{if } t = k \\\\\n",
    "        0 & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "If we define the auxiliary observation matrix: \n",
    "\n",
    "\\begin{align}\n",
    "    \\tilde{\\bm{{X}}} := \\bm{W}^\\frac{1}{2} \\bm{X}\n",
    "\\end{align}\n",
    "\n",
    "then we can see that the EWA-SC can be expressed in a similar form as the standard uniformly weighted sample covariance. The advantage of recasting the EWA-SC in this way is that many of the refinements for the standard sample covariance that have been developed over the years are at our disposal; including shrinkage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>03/01/2000</th>\n",
       "      <th>04/01/2000</th>\n",
       "      <th>05/01/2000</th>\n",
       "      <th>06/01/2000</th>\n",
       "      <th>07/01/2000</th>\n",
       "      <th>10/01/2000</th>\n",
       "      <th>11/01/2000</th>\n",
       "      <th>12/01/2000</th>\n",
       "      <th>13/01/2000</th>\n",
       "      <th>14/01/2000</th>\n",
       "      <th>...</th>\n",
       "      <th>13/12/2000</th>\n",
       "      <th>14/12/2000</th>\n",
       "      <th>15/12/2000</th>\n",
       "      <th>18/12/2000</th>\n",
       "      <th>19/12/2000</th>\n",
       "      <th>20/12/2000</th>\n",
       "      <th>21/12/2000</th>\n",
       "      <th>22/12/2000</th>\n",
       "      <th>26/12/2000</th>\n",
       "      <th>27/12/2000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>-0.012239</td>\n",
       "      <td>0.009429</td>\n",
       "      <td>0.044739</td>\n",
       "      <td>-0.011008</td>\n",
       "      <td>-0.015155</td>\n",
       "      <td>-0.030173</td>\n",
       "      <td>0.021279</td>\n",
       "      <td>-0.004943</td>\n",
       "      <td>-0.017157</td>\n",
       "      <td>-0.018955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037058</td>\n",
       "      <td>-0.002082</td>\n",
       "      <td>-0.008524</td>\n",
       "      <td>0.018609</td>\n",
       "      <td>0.040317</td>\n",
       "      <td>-0.051453</td>\n",
       "      <td>0.012609</td>\n",
       "      <td>0.072985</td>\n",
       "      <td>-0.007656</td>\n",
       "      <td>-0.009671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABM</th>\n",
       "      <td>-0.008622</td>\n",
       "      <td>0.011591</td>\n",
       "      <td>-0.005816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008755</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>-0.026964</td>\n",
       "      <td>0.011710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>-0.004303</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.015092</td>\n",
       "      <td>0.008568</td>\n",
       "      <td>-0.006436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052943</td>\n",
       "      <td>-0.029570</td>\n",
       "      <td>0.004304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABT</th>\n",
       "      <td>-0.006679</td>\n",
       "      <td>-0.012004</td>\n",
       "      <td>0.010437</td>\n",
       "      <td>0.030593</td>\n",
       "      <td>0.026866</td>\n",
       "      <td>-0.019806</td>\n",
       "      <td>0.010212</td>\n",
       "      <td>-0.020509</td>\n",
       "      <td>-0.008684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023227</td>\n",
       "      <td>-0.048372</td>\n",
       "      <td>0.030120</td>\n",
       "      <td>0.035326</td>\n",
       "      <td>0.026674</td>\n",
       "      <td>-0.025497</td>\n",
       "      <td>-0.013694</td>\n",
       "      <td>-0.018056</td>\n",
       "      <td>0.026508</td>\n",
       "      <td>-0.005458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADI</th>\n",
       "      <td>-0.033849</td>\n",
       "      <td>-0.041555</td>\n",
       "      <td>0.013614</td>\n",
       "      <td>-0.026050</td>\n",
       "      <td>0.031644</td>\n",
       "      <td>0.045277</td>\n",
       "      <td>-0.030045</td>\n",
       "      <td>0.032663</td>\n",
       "      <td>-0.019261</td>\n",
       "      <td>0.053811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100518</td>\n",
       "      <td>-0.026081</td>\n",
       "      <td>0.020950</td>\n",
       "      <td>-0.057097</td>\n",
       "      <td>0.036648</td>\n",
       "      <td>-0.003907</td>\n",
       "      <td>-0.057160</td>\n",
       "      <td>0.012197</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>0.070431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004954</td>\n",
       "      <td>-0.014950</td>\n",
       "      <td>0.010051</td>\n",
       "      <td>0.004936</td>\n",
       "      <td>-0.004913</td>\n",
       "      <td>-0.014900</td>\n",
       "      <td>0.019722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010586</td>\n",
       "      <td>-0.010234</td>\n",
       "      <td>0.030135</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>-0.009867</td>\n",
       "      <td>0.043721</td>\n",
       "      <td>-0.004794</td>\n",
       "      <td>0.014324</td>\n",
       "      <td>0.018730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XLY</th>\n",
       "      <td>-0.026868</td>\n",
       "      <td>-0.014942</td>\n",
       "      <td>-0.015635</td>\n",
       "      <td>0.004538</td>\n",
       "      <td>0.033271</td>\n",
       "      <td>-0.003860</td>\n",
       "      <td>-0.008233</td>\n",
       "      <td>-0.007799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003414</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020053</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>-0.008340</td>\n",
       "      <td>0.013062</td>\n",
       "      <td>-0.028330</td>\n",
       "      <td>0.021488</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.013630</td>\n",
       "      <td>-0.010994</td>\n",
       "      <td>0.043059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>-0.015621</td>\n",
       "      <td>-0.006850</td>\n",
       "      <td>0.035450</td>\n",
       "      <td>0.049661</td>\n",
       "      <td>-0.011006</td>\n",
       "      <td>-0.004901</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>0.019541</td>\n",
       "      <td>-0.019494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011374</td>\n",
       "      <td>-0.015365</td>\n",
       "      <td>-0.004711</td>\n",
       "      <td>0.026397</td>\n",
       "      <td>0.012999</td>\n",
       "      <td>-0.025376</td>\n",
       "      <td>-0.003127</td>\n",
       "      <td>0.023966</td>\n",
       "      <td>0.021202</td>\n",
       "      <td>-0.012793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XRX</th>\n",
       "      <td>0.032064</td>\n",
       "      <td>-0.044716</td>\n",
       "      <td>0.020201</td>\n",
       "      <td>0.007449</td>\n",
       "      <td>0.022010</td>\n",
       "      <td>-0.038799</td>\n",
       "      <td>-0.014900</td>\n",
       "      <td>0.007564</td>\n",
       "      <td>0.022286</td>\n",
       "      <td>-0.024678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035471</td>\n",
       "      <td>0.087359</td>\n",
       "      <td>0.032261</td>\n",
       "      <td>0.020985</td>\n",
       "      <td>0.051229</td>\n",
       "      <td>-0.043302</td>\n",
       "      <td>-0.117316</td>\n",
       "      <td>0.053774</td>\n",
       "      <td>-0.026896</td>\n",
       "      <td>0.040624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YUM</th>\n",
       "      <td>-0.030922</td>\n",
       "      <td>-0.011168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001611</td>\n",
       "      <td>-0.021204</td>\n",
       "      <td>0.038866</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>-0.014426</td>\n",
       "      <td>0.003188</td>\n",
       "      <td>-0.025827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028318</td>\n",
       "      <td>-0.029058</td>\n",
       "      <td>-0.007890</td>\n",
       "      <td>0.048308</td>\n",
       "      <td>0.009407</td>\n",
       "      <td>-0.051475</td>\n",
       "      <td>-0.050307</td>\n",
       "      <td>-0.010339</td>\n",
       "      <td>-0.010426</td>\n",
       "      <td>0.022858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTR</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>-0.035190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009016</td>\n",
       "      <td>-0.009020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007867</td>\n",
       "      <td>-0.014274</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>-0.012665</td>\n",
       "      <td>-0.009576</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>-0.016048</td>\n",
       "      <td>0.008070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>695 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        03/01/2000  04/01/2000  05/01/2000  06/01/2000  07/01/2000  \\\n",
       "ticker                                                               \n",
       "AA       -0.012239    0.009429    0.044739   -0.011008   -0.015155   \n",
       "ABM      -0.008622    0.011591   -0.005816    0.000000    0.002906   \n",
       "ABT      -0.006679   -0.012004    0.010437    0.030593    0.026866   \n",
       "ADI      -0.033849   -0.041555    0.013614   -0.026050    0.031644   \n",
       "ADM       0.000000    0.004954   -0.014950    0.010051    0.004936   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "XLY      -0.026868   -0.014942   -0.015635    0.004538    0.033271   \n",
       "XOM      -0.015621   -0.006850    0.035450    0.049661   -0.011006   \n",
       "XRX       0.032064   -0.044716    0.020201    0.007449    0.022010   \n",
       "YUM      -0.030922   -0.011168    0.000000   -0.001611   -0.021204   \n",
       "ZTR       0.000000    0.017715    0.008904    0.008825    0.008667   \n",
       "\n",
       "        10/01/2000  11/01/2000  12/01/2000  13/01/2000  14/01/2000  ...  \\\n",
       "ticker                                                              ...   \n",
       "AA       -0.030173    0.021279   -0.004943   -0.017157   -0.018955  ...   \n",
       "ABM       0.000000   -0.008755    0.002947   -0.026964    0.011710  ...   \n",
       "ABT      -0.019806    0.010212   -0.020509   -0.008684    0.000000  ...   \n",
       "ADI       0.045277   -0.030045    0.032663   -0.019261    0.053811  ...   \n",
       "ADM      -0.004913   -0.014900    0.019722    0.000000    0.028712  ...   \n",
       "...            ...         ...         ...         ...         ...  ...   \n",
       "XLY      -0.003860   -0.008233   -0.007799    0.000000   -0.003414  ...   \n",
       "XOM      -0.004901    0.002806    0.002824    0.019541   -0.019494  ...   \n",
       "XRX      -0.038799   -0.014900    0.007564    0.022286   -0.024678  ...   \n",
       "YUM       0.038866    0.001599   -0.014426    0.003188   -0.025827  ...   \n",
       "ZTR       0.008671   -0.035190    0.000000   -0.009016   -0.009020  ...   \n",
       "\n",
       "        13/12/2000  14/12/2000  15/12/2000  18/12/2000  19/12/2000  \\\n",
       "ticker                                                               \n",
       "AA        0.037058   -0.002082   -0.008524    0.018609    0.040317   \n",
       "ABM       0.017241   -0.004303    0.002164    0.015092    0.008568   \n",
       "ABT       0.023227   -0.048372    0.030120    0.035326    0.026674   \n",
       "ADI      -0.100518   -0.026081    0.020950   -0.057097    0.036648   \n",
       "ADM       0.000000    0.010586   -0.010234    0.030135    0.004875   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "XLY      -0.020053    0.000678   -0.008340    0.013062   -0.028330   \n",
       "XOM       0.011374   -0.015365   -0.004711    0.026397    0.012999   \n",
       "XRX       0.035471    0.087359    0.032261    0.020985    0.051229   \n",
       "YUM      -0.028318   -0.029058   -0.007890    0.048308    0.009407   \n",
       "ZTR      -0.007867   -0.014274    0.004775    0.001599    0.004787   \n",
       "\n",
       "        20/12/2000  21/12/2000  22/12/2000  26/12/2000  27/12/2000  \n",
       "ticker                                                              \n",
       "AA       -0.051453    0.012609    0.072985   -0.007656   -0.009671  \n",
       "ABM      -0.006436    0.000000    0.052943   -0.029570    0.004304  \n",
       "ABT      -0.025497   -0.013694   -0.018056    0.026508   -0.005458  \n",
       "ADI      -0.003907   -0.057160    0.012197    0.012939    0.070431  \n",
       "ADM      -0.009867    0.043721   -0.004794    0.014324    0.018730  \n",
       "...            ...         ...         ...         ...         ...  \n",
       "XLY       0.021488    0.033561    0.013630   -0.010994    0.043059  \n",
       "XOM      -0.025376   -0.003127    0.023966    0.021202   -0.012793  \n",
       "XRX      -0.043302   -0.117316    0.053774   -0.026896    0.040624  \n",
       "YUM      -0.051475   -0.050307   -0.010339   -0.010426    0.022858  \n",
       "ZTR      -0.012665   -0.009576    0.004800   -0.016048    0.008070  \n",
       "\n",
       "[695 rows x 250 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################### 1. We start by randomizing the auxiliary observation matrix  ̃X from Equation (5) along the time axis #########################\n",
    "def auxilary_matrix(days, beta, df_cleaned):\n",
    "\n",
    "    ## 1. We extract the data corresponding to the returns of our assets (columns) during these d days (lines)\n",
    "    X = df_cleaned.iloc[0:days,:] ## shape days * number of stocks\n",
    "\n",
    "    ## 2. We slightly adjust the matrix of observations to get the auxiliary matrix that puts more weight on recent dates\n",
    "\n",
    "    W = np.sqrt(np.diag(days * (1 - beta) * beta**(np.arange(days)[::-1]) / (1 - beta**days)))  # Compute the weight matrix\n",
    "    X_tilde = pd.DataFrame(index=X.index, columns=X.columns, data=np.dot(W, X)).transpose()\n",
    "\n",
    "    ## 3. We randomize the auxiliary matrix of observations according to the time axis\n",
    "    # Randomized_X = X_tilde.transpose().sample(frac=1, axis=1, random_state=42) ## we transpose X as we want to have daily observations of the whole dataset !\n",
    "\n",
    "    return X_tilde\n",
    "\n",
    "# ---------------------------------------------------------------- TESTS ----------------------------------------------------------------\n",
    "\n",
    "days = 250\n",
    "beta = 0.999\n",
    "X_tilde = auxilary_matrix(days=days, beta=beta, df_cleaned=df_cleaned)\n",
    "X_tilde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the (randomized) auxiliary observations into $K$ non-overlapping folds **of equal size** represented as $\\{\\mathcal{I}_k | \\mathcal{I}_k \\subset \\{1, ..., K\\}\\}_{k=1}^K$. Each set indexed by $\\mathcal{I}_k$ works as a **\"test\" fold**, while the remaining observations' indices constitute a **\"training\" fold**,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.  , ..., -0.  , -0.05,  0.03],\n",
       "       [ 0.09,  0.17, -0.18, ..., -0.01,  0.  ,  0.02],\n",
       "       [ 0.18,  0.02, -0.1 , ..., -0.  , -0.04,  0.01],\n",
       "       ...,\n",
       "       [ 0.01,  0.01,  0.02, ...,  0.04,  0.03,  0.03],\n",
       "       [ 0.01,  0.02, -0.01, ..., -0.02, -0.05,  0.04],\n",
       "       [-0.  ,  0.01,  0.03, ...,  0.01,  0.  ,  0.01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "######################### 2. We then split the (randomized) auxiliary observations into K non-overlapping folds of equal size #########################\n",
    "def shuffle_split(data, K):\n",
    "    # Initialize ShuffleSplit\n",
    "    shuffle_split = ShuffleSplit(n_splits=K, test_size=0.2, random_state=42) \n",
    "    # test_size=0.2 : 20% des données pour l'ensemble de test, 80% pour l'ensemble d'entraînement.\n",
    "\n",
    "    # Create empty list to store splits\n",
    "    splits = []\n",
    "\n",
    "    # Perform shuffling and splitting\n",
    "    for train_index, test_index in shuffle_split.split(data.columns):\n",
    "        train_fold = [data.columns[i] for i in train_index]\n",
    "        test_fold = [data.columns[i] for i in test_index]\n",
    "        splits.append((train_fold, test_fold)) ## attention à cette structure\n",
    "\n",
    "    return splits\n",
    "\n",
    "######################### 3. For each K fold configuration, we estimate the sample eigenvectors from the training set #########################\n",
    "def eigen_sample(data, train_fold): ## we train the data on this test fold\n",
    "\n",
    "    train_data = data.loc[:, train_fold]\n",
    "\n",
    "    # Calculer la moyenne de l'ensemble d'entraînement\n",
    "    mean_train = np.mean(train_data, axis=1)\n",
    "\n",
    "    # Centrer les données d'entraînement\n",
    "    centered_train_data = train_data.sub(mean_train, axis=0)\n",
    "\n",
    "    # Calculer la matrice de covariance des données d'entraînement\n",
    "    cov_matrix_train = np.cov(centered_train_data) ## size number of assets * number of assets\n",
    "\n",
    "    # Calculer les vecteurs et valeurs propres de la matrice de covariance\n",
    "    _, eigenvectors_train = np.linalg.eigh(cov_matrix_train) ## .eigh and not .eig so that the eigenvalues are real \n",
    "\n",
    "    return eigenvectors_train\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------- TESTS ----------------------------------------------------------------\n",
    "days = 250\n",
    "beta = 0.999\n",
    "X_tilde = auxilary_matrix(days=days, beta=beta, df_cleaned=df_cleaned)\n",
    "splits = shuffle_split(data=X_tilde, K=20)\n",
    "eigenvector = eigen_sample(data=X_tilde, train_fold=splits[0][0])\n",
    "eigenvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a fixed exponential decay rate $\\beta \\in (0, 1)$ an its associated EWA-SC $\\bm{E}$. Remember we denoted $\\bm{\\Sigma}$ the \"true\" and unobserved covariance matrix. Both these matrices are symmetric and thus admit the following spectral decomposition: \n",
    "\n",
    "\\begin{equation}\n",
    "\\bm{E} = \\sum_{i=1}^{n} \\hat{\\lambda}_i \\hat{u}_i \\hat{u}_i', \\quad \\text{and} \\quad \\bm{\\Sigma} = \\sum_{i=1}^{n} \\lambda_i u_i u_i',\n",
    "\\end{equation}\n",
    "\n",
    "where $(\\hat{\\lambda}_1, \\ldots, \\hat{\\lambda}_n; \\hat{u}_1, \\ldots, \\hat{u}_n)$  denotes a system of sample eigenvalues and eigenvectors of $\\bm{E}$, and $(\\lambda_1, \\ldots, \\lambda_n; u_1, \\ldots, u_n)$ denotes a system of eigenvalues and eigenvectors of the \"true\" covariance $\\bm{\\Sigma}$. The eigenvalues are assumed to be sorted in ascending order.\n",
    "\n",
    "To correct the bias previously mentioned, we consider a specific framework where the sample eigenvalues should be corrected while retaining the sample eigenvectors of the original matrix. This is mathematically tantamount to write:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{\\bm{\\Sigma}} = \\sum_{i=1}^{n} \\xi_i \\hat{u}_i \\hat{u}_i',\n",
    "\\end{equation}\n",
    "\n",
    "where $\\bm{\\xi} = (\\xi_i)_{i=1,...,n}$  is an $n$-dimensional vector that we have to obtain. This framework is somewhat reasonable as, in absence of any **a priori** knowledge about the structure of the covariance matrix, the most natural guess that we have about the population eigenvectors is the sample eigenvectors that we observe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### 3. For each K fold configuration, we estimate the sample eigenvectors from the training set #########################\n",
    "def eigen_sample(data, train_fold): ## we train the data on this test fold\n",
    "\n",
    "    train_data = data.loc[:, train_fold]\n",
    "\n",
    "    # Calculer la moyenne de l'ensemble d'entraînement\n",
    "    mean_train = np.mean(train_data, axis=1)\n",
    "\n",
    "    # Centrer les données d'entraînement\n",
    "    centered_train_data = train_data.sub(mean_train, axis=0)\n",
    "\n",
    "    # Calculer la matrice de covariance des données d'entraînement\n",
    "    cov_matrix_train = np.cov(centered_train_data) ## size number of assets * number of assets\n",
    "\n",
    "    # Calculer les vecteurs et valeurs propres de la matrice de covariance\n",
    "    _, eigenvectors_train = np.linalg.eigh(cov_matrix_train) ## .eigh and not .eig so that the eigenvalues are real \n",
    "\n",
    "    return eigenvectors_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each $K$ fold configuration, we estimate the sample eigenvectors from the training set and then estimate an N-dimensional vector of out-of-sample variances using the test set and the sample eigenvectors. \n",
    "\n",
    "- Finally, we average the out-of-sample variance estimates over $K$ to give us the bias-corrected eigenvalue of the ith sample eigenvector portfolio denoted as $\\xi^{\\dagger}_i$ for all $i$.\n",
    "\n",
    "These two last steps are equivalent to introducing the $K$-fold cross-validation estimator:\n",
    "\n",
    "$$\n",
    "\\xi^{\\dagger}_i := \\frac{1}{K} \\sum_{k=1}^K \\sum_{t \\in \\mathcal{I}_k}  \\frac{1}{\\lvert \\mathcal{I}_k \\rvert} \\left(\\hat{u}_i[k]'\\tilde{x}_t \\right)^2, \\quad \\text{for } i = 1, \\ldots, n,\n",
    "$$\n",
    "\n",
    "where: \n",
    "- $\\lvert \\mathcal{I}_k \\rvert$ denotes the cardinality of the kth test set such that each of them is approximately equal in size, that is, $K \\lvert \\mathcal{I}_k \\rvert \\approx d$\n",
    "- Here, $\\hat{u}_i[k]$ is the $i$-th sample eigenvector of a sample covariance matrix that is obtained from the training fold, and $\\tilde{x}$ is a sample vector of the auxiliary observation matrix from the test fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005555442500824901"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def intra_fold_loss(data, test_fold, sample_eigenvector_i, beta): ## we test the data on this test fold\n",
    "\n",
    "    ## 1. get the fold cardinality \n",
    "    fold_cardinality = len(test_fold)\n",
    "\n",
    "    ## 2. sample vector of the auxiliary observation matrix from the test fold (inspired from the code above)\n",
    "\n",
    "    days = len(test_fold)\n",
    "    X = data.loc[:,test_fold].transpose()\n",
    "\n",
    "    ## 2. We slightly adjust the matrix of observations to get the auxiliary matrix that puts more weight on recent dates\n",
    "\n",
    "    W = np.sqrt(np.diag(days * (1 - beta) * beta**(np.arange(days)[::-1]) / (1 - beta**days)))  # Compute the weight matrix\n",
    "    X_tilde = pd.DataFrame(index=X.index, columns=X.columns, data=np.dot(W, X)).transpose()\n",
    "\n",
    "    res = (np.dot(sample_eigenvector_i, X_tilde) ** 2) / fold_cardinality\n",
    "    result = np.sum(res)\n",
    "\n",
    "    return result\n",
    "\n",
    "# ---------------------------------------------------------------- TESTS ----------------------------------------------------------------\n",
    "beta = 0.99\n",
    "data = X_tilde\n",
    "sample_eigenvector_i = eigenvector[0]\n",
    "X = X_tilde.loc[:, splits[0][1]]\n",
    "test_fold = splits[0][1]\n",
    "intra_loss = intra_fold_loss(data=data, test_fold=splits[0][1], sample_eigenvector_i=sample_eigenvector_i, beta=beta)\n",
    "intra_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "average_loss_i() got an unexpected keyword argument 'days'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/EMA_CV.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/EMA_CV.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/EMA_CV.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# ---------------------------------------------------------------- TEST ----------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/EMA_CV.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m average_loss_i \u001b[39m=\u001b[39m average_loss_i(df_cleaned\u001b[39m==\u001b[39;49mdf_cleaned, days\u001b[39m=\u001b[39;49m\u001b[39m250\u001b[39;49m, splits\u001b[39m=\u001b[39;49msplits, index\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, beta\u001b[39m=\u001b[39;49m\u001b[39m0.99\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: average_loss_i() got an unexpected keyword argument 'days'"
     ]
    }
   ],
   "source": [
    "def average_loss_i(data, splits, index, beta):\n",
    "\n",
    "    res = 0 ## to stock the overall loss\n",
    "\n",
    "    for (train_fold, test_fold) in splits:\n",
    "\n",
    "        ## sur chaque fold, on calcule les sample eigenvectors à partir du training fold correspondant\n",
    "\n",
    "        sample_eigenvector_i = eigen_sample(data=data, train_fold=train_fold)[index] ## on ne garde que l'eigenvector correspondant au bon index\n",
    "\n",
    "        ## sur chaque fold, on calcule la perte au sein du fold à partir de l'échantillon de test\n",
    "\n",
    "        res = res + intra_fold_loss(data=data, test_fold=test_fold, sample_eigenvector_i=sample_eigenvector_i, beta=beta)\n",
    "\n",
    "    res = res / len(splits) ## we average by the number of folds (which corresponds to the lengths of the splits)\n",
    "\n",
    "    return res\n",
    "\n",
    "# ---------------------------------------------------------------- TEST ----------------------------------------------------------------\n",
    "average_loss_i = average_loss_i(df_cleaned==df_cleaned, days=250, splits=splits, index=0, beta=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (4.66.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calcul en cours:   0%|          | 0/695 [00:00<?, ?itération/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calcul en cours: 100%|██████████| 695/695 [14:56<00:00,  1.29s/itération]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def eigenvalue_estimator(df_cleaned, days, K, beta):\n",
    "\n",
    "    data = auxilary_matrix(days=days, beta=beta, df_cleaned=df_cleaned)\n",
    "    \n",
    "    splits = shuffle_split(data=data, K=K)\n",
    "\n",
    "    number_of_stocks = data.shape[0]\n",
    "\n",
    "    x = np.zeros(number_of_stocks)  # initialisation de x\n",
    "    for i in tqdm(range(number_of_stocks), desc='Calcul en cours', unit='itération'):\n",
    "        x[i] = average_loss_i(data=data, splits=splits, index=i, beta=beta)                  \n",
    "    return x\n",
    "\n",
    "# ---------------------------------------------------------------- TEST ----------------------------------------------------------------\n",
    "eigenvalue_estimator = eigenvalue_estimator(df_cleaned=df_cleaned, days=250, K=10, beta=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0005793698, 0.0006946351, 0.0005185658, 0.0005557637,\n",
       "       0.0007370129, 0.0006402375, 0.0007496107, 0.0005882843,\n",
       "       0.0006812528, 0.000712892 , 0.0007119005, 0.0006731959,\n",
       "       0.0006026536, 0.0006816077, 0.0008599714, 0.000699467 ,\n",
       "       0.0006363773, 0.0006076935, 0.000674776 , 0.0006844753,\n",
       "       0.0006404914, 0.000710006 , 0.0007268464, 0.00070062  ,\n",
       "       0.0008231383, 0.0006831348, 0.0006576698, 0.0006986462,\n",
       "       0.0008627604, 0.0007062771, 0.0007055713, 0.0008411223,\n",
       "       0.0007038183, 0.0006542016, 0.0007606853, 0.0005879162,\n",
       "       0.00050023  , 0.0006409119, 0.000617538 , 0.0006124384,\n",
       "       0.0006893665, 0.000692577 , 0.0007031964, 0.0006046827,\n",
       "       0.0007651305, 0.0007379627, 0.0007058259, 0.0006575152,\n",
       "       0.0006693998, 0.000893408 , 0.0005392596, 0.0006265962,\n",
       "       0.0005682921, 0.0007374273, 0.0007622489, 0.000735299 ,\n",
       "       0.0005628294, 0.0006271214, 0.0006132104, 0.0006548223,\n",
       "       0.0006209698, 0.0007186939, 0.0006543316, 0.0006545529,\n",
       "       0.0007500565, 0.0006512258, 0.0007137334, 0.0006721202,\n",
       "       0.0007289484, 0.0007117431, 0.000807454 , 0.0008057719,\n",
       "       0.0006405979, 0.000686463 , 0.0006972328, 0.0006838908,\n",
       "       0.0004886022, 0.0006528832, 0.0007625087, 0.0006005052,\n",
       "       0.0007718498, 0.0006599919, 0.0007194647, 0.0005998362,\n",
       "       0.000607121 , 0.0005382825, 0.0005763143, 0.00074296  ,\n",
       "       0.0006108668, 0.0005756358, 0.0005983658, 0.0007556534,\n",
       "       0.0007535823, 0.0005743066, 0.0006819317, 0.000606439 ,\n",
       "       0.0007253521, 0.0006632519, 0.0006267913, 0.0006509284,\n",
       "       0.0006628508, 0.0005688121, 0.0005734546, 0.0007187686,\n",
       "       0.000705922 , 0.0006028383, 0.0007916384, 0.0006891035,\n",
       "       0.0006477548, 0.0005790634, 0.0007194431, 0.0005947697,\n",
       "       0.0006947115, 0.000631713 , 0.0007032034, 0.0006557751,\n",
       "       0.0006237732, 0.0007017587, 0.0006179626, 0.0006599067,\n",
       "       0.0005854391, 0.0005560288, 0.0007076324, 0.0006254489,\n",
       "       0.0006980514, 0.0006350523, 0.00061833  , 0.0006626582,\n",
       "       0.0006026897, 0.0006289938, 0.0006545845, 0.0006417951,\n",
       "       0.0006905217, 0.0007645997, 0.0007017338, 0.0006288876,\n",
       "       0.0006253336, 0.0006517059, 0.0006096299, 0.0006836271,\n",
       "       0.0006440371, 0.00064856  , 0.0006064915, 0.0006760414,\n",
       "       0.0007823438, 0.0005846684, 0.0006448599, 0.0006246139,\n",
       "       0.0007406352, 0.0006814513, 0.0006996655, 0.0007221313,\n",
       "       0.0006207021, 0.0007995928, 0.0007877086, 0.0007001832,\n",
       "       0.0005815803, 0.000706441 , 0.0006394474, 0.0005965483,\n",
       "       0.0006383323, 0.0006716675, 0.0006570635, 0.0006840545,\n",
       "       0.0006739618, 0.0006487422, 0.0006486378, 0.0007878369,\n",
       "       0.0006557359, 0.0007715654, 0.0007263385, 0.0005887889,\n",
       "       0.0005807633, 0.0007539131, 0.0005920424, 0.0005652663,\n",
       "       0.000659478 , 0.0007084557, 0.0006986114, 0.0005491683,\n",
       "       0.0008176041, 0.0006310395, 0.0006802637, 0.0006515618,\n",
       "       0.0006588146, 0.0005516808, 0.0005811487, 0.0006410438,\n",
       "       0.0006655409, 0.0006446382, 0.0006162291, 0.0006256891,\n",
       "       0.000603896 , 0.0007887789, 0.0006224991, 0.0005423351,\n",
       "       0.0006112775, 0.0007100773, 0.0006594109, 0.00074622  ,\n",
       "       0.0006824863, 0.0007094156, 0.0006527143, 0.0007343513,\n",
       "       0.000702777 , 0.0006173957, 0.0006403091, 0.0005729019,\n",
       "       0.0006904233, 0.0006566689, 0.0006599014, 0.0006685012,\n",
       "       0.000615331 , 0.0006610033, 0.0007139272, 0.0007499321,\n",
       "       0.000606518 , 0.0008330172, 0.0006499679, 0.0006473071,\n",
       "       0.0008210277, 0.0006543983, 0.0007078625, 0.0006911086,\n",
       "       0.0006324841, 0.0006893246, 0.0007965793, 0.0005742477,\n",
       "       0.0007091333, 0.0007375474, 0.0006406109, 0.0005719907,\n",
       "       0.0005752176, 0.0006914791, 0.0005921391, 0.0006777886,\n",
       "       0.0006048475, 0.0006056103, 0.0006587333, 0.000678831 ,\n",
       "       0.0006709235, 0.0007596992, 0.0006941072, 0.0008095615,\n",
       "       0.0006813265, 0.0005724376, 0.0007053797, 0.0005423847,\n",
       "       0.0006194347, 0.0006896967, 0.0008939646, 0.0005707949,\n",
       "       0.0007180679, 0.00063083  , 0.0005803701, 0.0005679927,\n",
       "       0.0006572066, 0.0007298476, 0.0007281723, 0.0006329837,\n",
       "       0.0005862398, 0.0006474777, 0.0006556983, 0.0007470148,\n",
       "       0.000681165 , 0.0006590827, 0.0006463461, 0.000649972 ,\n",
       "       0.0006948839, 0.0006368585, 0.0006708668, 0.0006126179,\n",
       "       0.0005577349, 0.0008025579, 0.0006631596, 0.000750207 ,\n",
       "       0.0007786057, 0.0006545465, 0.0006791567, 0.0007565848,\n",
       "       0.0006549755, 0.0006433241, 0.0005638154, 0.0006915352,\n",
       "       0.0006873478, 0.0007093882, 0.0005469076, 0.0006705618,\n",
       "       0.0006353569, 0.00070966  , 0.0006587062, 0.0005573381,\n",
       "       0.0006227156, 0.0006915018, 0.0008397285, 0.0006274683,\n",
       "       0.0006552609, 0.0006443459, 0.0005892156, 0.0008624891,\n",
       "       0.0006268877, 0.0007146233, 0.0006501935, 0.0006034916,\n",
       "       0.0008031761, 0.0006807057, 0.0005577471, 0.0006528854,\n",
       "       0.0005750915, 0.0006849315, 0.0005691455, 0.0006927611,\n",
       "       0.0006639143, 0.0006749561, 0.0006096508, 0.0006330622,\n",
       "       0.0006008391, 0.000612861 , 0.0007229965, 0.0005942101,\n",
       "       0.000701778 , 0.0008458203, 0.0005329492, 0.0005793374,\n",
       "       0.0005626571, 0.0007648316, 0.0006435875, 0.0007590229,\n",
       "       0.0006662952, 0.0009537308, 0.0006113298, 0.0006600564,\n",
       "       0.0007780343, 0.0005998415, 0.0006440443, 0.0006186557,\n",
       "       0.0004201784, 0.0008521465, 0.0006732373, 0.0007965474,\n",
       "       0.0008672172, 0.0007125197, 0.00064455  , 0.0006027617,\n",
       "       0.0006645232, 0.0006144799, 0.0007494758, 0.0006934999,\n",
       "       0.0007117155, 0.0005435119, 0.0005980314, 0.0005895151,\n",
       "       0.0007048673, 0.0006711724, 0.0006575362, 0.0007946971,\n",
       "       0.0007213202, 0.0005999085, 0.000801998 , 0.0007502902,\n",
       "       0.0006874055, 0.0007926237, 0.0007054625, 0.0008113487,\n",
       "       0.0006087265, 0.0008059771, 0.0007841654, 0.0008037231,\n",
       "       0.0007589782, 0.0006466105, 0.000761354 , 0.0006220383,\n",
       "       0.0008456648, 0.0005660744, 0.0005813723, 0.0008058628,\n",
       "       0.0007087718, 0.0007002343, 0.0007000511, 0.0007929582,\n",
       "       0.0008510976, 0.0006391017, 0.0007338988, 0.0005511293,\n",
       "       0.0005309008, 0.0006707197, 0.000675358 , 0.0006020016,\n",
       "       0.0006857445, 0.0008744291, 0.000680818 , 0.0008077756,\n",
       "       0.0008227881, 0.0007953474, 0.0008633886, 0.0006180913,\n",
       "       0.0006136888, 0.000755896 , 0.0007481009, 0.0006889733,\n",
       "       0.0007306915, 0.0007743394, 0.0006054504, 0.0006795072,\n",
       "       0.0006595584, 0.0007345452, 0.0006299404, 0.0006905368,\n",
       "       0.0008238127, 0.0007316114, 0.0007603059, 0.0006326815,\n",
       "       0.0007694106, 0.0006574258, 0.0006810109, 0.0006392406,\n",
       "       0.0007309812, 0.0008236477, 0.0007080784, 0.0008076191,\n",
       "       0.0007670009, 0.0007829346, 0.0008288837, 0.0005756991,\n",
       "       0.000824796 , 0.0007390123, 0.0007197572, 0.0005941765,\n",
       "       0.0006272211, 0.0006522076, 0.0005944966, 0.0007021085,\n",
       "       0.000702985 , 0.000711664 , 0.0006781105, 0.0006459555,\n",
       "       0.0006900879, 0.0006587779, 0.0007683542, 0.0006349894,\n",
       "       0.0006703037, 0.0006486651, 0.0007398285, 0.0007746044,\n",
       "       0.0006024501, 0.000671622 , 0.0007898067, 0.0006494189,\n",
       "       0.0005958646, 0.0007051712, 0.0006793521, 0.0007442617,\n",
       "       0.0007313523, 0.0007014035, 0.0007369499, 0.0007671731,\n",
       "       0.0006292223, 0.0006814304, 0.0006656883, 0.0007264956,\n",
       "       0.0007047576, 0.000705596 , 0.0006019087, 0.0006504972,\n",
       "       0.0006315631, 0.000576244 , 0.0007659895, 0.0006574589,\n",
       "       0.0005949598, 0.000664159 , 0.0007049621, 0.000606567 ,\n",
       "       0.0006589853, 0.000782817 , 0.0006154977, 0.0007058769,\n",
       "       0.000765796 , 0.0006453905, 0.0006107059, 0.0007812298,\n",
       "       0.0007582202, 0.0007905938, 0.0006043908, 0.0008121263,\n",
       "       0.0005915399, 0.00068226  , 0.0005839579, 0.0005573633,\n",
       "       0.0006564763, 0.0007617875, 0.0006444788, 0.0007601487,\n",
       "       0.0007411391, 0.0005809574, 0.000862279 , 0.0007188741,\n",
       "       0.0006642825, 0.0007064208, 0.0007021842, 0.0006288383,\n",
       "       0.0007116616, 0.0006098664, 0.0005787465, 0.0006866   ,\n",
       "       0.0006960232, 0.0006691682, 0.0006561961, 0.0008149273,\n",
       "       0.0006580829, 0.0006347201, 0.0006999837, 0.0007431279,\n",
       "       0.0007703852, 0.0006865425, 0.0006655754, 0.0008621572,\n",
       "       0.0005949087, 0.0006108398, 0.0006391962, 0.0007377118,\n",
       "       0.0006448169, 0.0006802024, 0.0007083747, 0.0005170108,\n",
       "       0.0007789431, 0.0008362577, 0.000709987 , 0.0006509237,\n",
       "       0.0007656828, 0.000556838 , 0.0008157292, 0.0006734848,\n",
       "       0.0006294442, 0.0005928686, 0.0006426218, 0.0006140884,\n",
       "       0.0007940184, 0.0007319853, 0.0007701545, 0.0006196302,\n",
       "       0.0005655189, 0.0006679404, 0.0007178687, 0.0006394345,\n",
       "       0.0007141519, 0.0006876725, 0.0006512398, 0.000598324 ,\n",
       "       0.0007433313, 0.0007191341, 0.0007338665, 0.0007780942,\n",
       "       0.0006339423, 0.0007916086, 0.0006619643, 0.000556568 ,\n",
       "       0.0008093132, 0.0006376955, 0.000600528 , 0.0006551105,\n",
       "       0.000576484 , 0.0006173353, 0.0006396844, 0.0006160779,\n",
       "       0.0008081098, 0.000752275 , 0.0007271432, 0.0006710274,\n",
       "       0.0006295927, 0.0007300369, 0.0006894287, 0.0005620829,\n",
       "       0.0006567381, 0.0006373061, 0.0007399417, 0.0006952151,\n",
       "       0.000644871 , 0.0005481172, 0.0006110245, 0.0005817207,\n",
       "       0.000561185 , 0.0006382596, 0.0006884303, 0.0005718728,\n",
       "       0.0006775013, 0.0006887061, 0.0006585316, 0.0008080351,\n",
       "       0.0006220623, 0.0007524094, 0.0006503345, 0.0007094957,\n",
       "       0.000604387 , 0.000623849 , 0.0006517608, 0.0006925091,\n",
       "       0.0006229015, 0.0005727179, 0.0005669004, 0.0006502344,\n",
       "       0.0005778704, 0.0006503721, 0.0006182516, 0.0006729531,\n",
       "       0.0005821718, 0.0006547237, 0.0006748362, 0.0006947887,\n",
       "       0.0007029557, 0.0005976343, 0.000713088 , 0.0006708554,\n",
       "       0.0006472658, 0.0006273834, 0.0006672302, 0.0009068833,\n",
       "       0.0006624551, 0.0006226121, 0.0007044153, 0.0006545938,\n",
       "       0.0006717127, 0.0006675187, 0.000617857 , 0.0006101934,\n",
       "       0.0007042609, 0.0004864025, 0.0008550763, 0.0004831729,\n",
       "       0.0005706717, 0.0005998092, 0.0007993081, 0.0006737743,\n",
       "       0.0006997581, 0.0006805873, 0.0006444847, 0.0008082517,\n",
       "       0.0006363307, 0.0007630228, 0.0006101077, 0.0006795847,\n",
       "       0.0008025132, 0.0007160789, 0.0005621351, 0.0006494827,\n",
       "       0.0007517079, 0.0005934458, 0.0007191363, 0.0007062951,\n",
       "       0.000684321 , 0.0007934274, 0.0006501249, 0.0008331349,\n",
       "       0.0007163673, 0.0006128102, 0.0006328168, 0.0005357755,\n",
       "       0.0006214211, 0.0006830414, 0.0006456778, 0.0006661082,\n",
       "       0.0007118021, 0.0007265052, 0.0007305065, 0.0007706252,\n",
       "       0.0007486756, 0.0007083356, 0.0005838351, 0.0007192387,\n",
       "       0.0008344764, 0.0006487844, 0.0006339207, 0.0006366464,\n",
       "       0.0005563128, 0.0005985508, 0.0007681885, 0.0006808746,\n",
       "       0.0006754885, 0.0006932298, 0.0008196081, 0.0006686983,\n",
       "       0.0006794262, 0.0007384664, 0.0007330228, 0.0006747634,\n",
       "       0.0007326865, 0.0006951925, 0.0006667674, 0.000756952 ,\n",
       "       0.0005964045, 0.0006386445, 0.0006377576, 0.0006518472,\n",
       "       0.0005768647, 0.0006212951, 0.0008003022])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=10)\n",
    "\n",
    "eigenvalue_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EWA_CV(eigenvalue_estimator, data, days):\n",
    "    X = df_cleaned.iloc[0:days,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 250\n",
    "beta = 0.99\n",
    "\n",
    "## compute the sample exponential moving average correlation matrix\n",
    "X = df_cleaned.iloc[0:days,:]\n",
    "W = np.sqrt(np.diag(days * (1 - beta) * beta**(np.arange(days)[::-1]) / (1 - beta**days)))  # Compute the weight matrix\n",
    "res1 = np.dot(X.T, W)  # Produit matriciel de X' et W\n",
    "S = np.dot(res1, X)\n",
    "\n",
    "## compute the eigenvectors of S\n",
    "\n",
    "_, eigenvectors = np.linalg.eig(S)\n",
    "\n",
    "## computes the estimator \n",
    "\n",
    "# Tailles des matrices\n",
    "num_eigenvalues = eigenvalue_estimator.shape[0]\n",
    "num_features = eigenvectors.shape[0]\n",
    "\n",
    "# Initialisation de Sigma avec des zéros\n",
    "Sigma = np.zeros((num_features, num_features), dtype=np.complex128)\n",
    "\n",
    "# Parcourir chaque vecteur propre et valeur propre\n",
    "for i in range(num_eigenvalues):\n",
    "    xi_dagger = eigenvalue_estimator[i]  # Conjugue de xi\n",
    "    ui = eigenvectors[:, i]  # i-ème vecteur propre\n",
    "\n",
    "    # Calcul du produit externe xi^† * ui * ui^† et addition à Sigma\n",
    "    Sigma += np.outer(xi_dagger, ui) @ np.conj(ui).reshape(-1, 1)\n",
    "\n",
    "# Sigma est maintenant la somme des produits xi^† * ui * ui^†\n",
    "Sigma = pd.DataFrame(index=df_cleaned.columns, columns=df_cleaned.columns, data=np.real(Sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.028117201 +0.j, -0.067523087 +0.j, -0.0016752846+0.j, ...,\n",
       "         0.          +0.j,  0.          +0.j,  0.          +0.j],\n",
       "       [-0.0238146008+0.j, -0.0035941907+0.j,  0.0205087932+0.j, ...,\n",
       "         0.          +0.j,  0.          +0.j,  0.          +0.j],\n",
       "       [ 0.0022368459+0.j, -0.044970012 +0.j,  0.0078269369+0.j, ...,\n",
       "         0.          +0.j,  0.          +0.j,  0.          +0.j],\n",
       "       ...,\n",
       "       [-0.0328243624+0.j,  0.0523596618+0.j, -0.051738209 +0.j, ...,\n",
       "         0.          +0.j,  0.          +0.j,  0.          +0.j],\n",
       "       [-0.0383655607+0.j, -0.0453393156+0.j,  0.0258260051+0.j, ...,\n",
       "         0.          +0.j,  0.          +0.j,  0.          +0.j],\n",
       "       [-0.007976776 +0.j,  0.0027771308+0.j, -0.0078436884+0.j, ...,\n",
       "         0.          +0.j,  0.          +0.j,  0.          +0.j]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
