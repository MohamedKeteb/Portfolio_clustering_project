{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import process\n",
    "import numpy as np \n",
    "# Jerome path : r'C:\\Users\\33640\\OneDrive\\Documents\\GitHub\\Portfolio_clustering_project\\Data\\DataBase.csv'\n",
    "# Nail path : '/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DataBase.csv'\n",
    "df = pd.read_csv(r'/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Data/DataBase.csv')\n",
    "\n",
    "df.set_index('ticker', inplace=True)\n",
    "\n",
    "df.columns = pd.to_datetime(df.columns.str[1:], format='%Y%m%d').strftime('%d/%m/%Y')\n",
    "\n",
    "df_cleaned = df.fillna(0) # Utilisez la méthode fillna(0) pour remplacer les NaN par 0\n",
    "\n",
    "df_cleaned = df_cleaned.transpose() ## WE WANT COLUMNS TO BE VECTOR OF RETURN FOR A GIVEN TICKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/cvxpy/reductions/solvers/solving_chain.py:336: FutureWarning: \n",
      "    Your problem is being solved with the ECOS solver by default. Starting in \n",
      "    CVXPY 1.5.0, Clarabel will be used as the default solver instead. To continue \n",
      "    using ECOS, specify the ECOS solver explicitly using the ``solver=cp.ECOS`` \n",
      "    argument to the ``problem.solve`` method.\n",
      "    \n",
      "  warnings.warn(ECOS_DEPRECATION_MSG, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "def cov_forecast(beta, lookback_window, number_folds, historical_data):\n",
    "\n",
    "    N = len(historical_data.columns)  # Number of assets, BEWARE TO THE SHAPE OF THE DATA FOR\n",
    "\n",
    "    Ik_length = int((lookback_window[1]-lookback_window[0])/number_folds) # Number of days in each fold for the cross validation, has to be an integer\n",
    "\n",
    "    # Initialize epsilon as a zero array with N elements\n",
    "    epsilon = np.zeros(N)\n",
    "\n",
    "    for k in range(number_folds):\n",
    "        # Calculate EWA matrix \n",
    "        weighted_matrices = [(beta**(Ik_length-t)) * np.outer(historical_data.iloc[t + Ik_length*k], historical_data.iloc[t + Ik_length*k]) for t in range(Ik_length)]\n",
    "        summed_weighted_matrices = np.sum(weighted_matrices, axis=0)\n",
    "        E_matrix = (1 - beta) / (1 - beta**Ik_length) * summed_weighted_matrices\n",
    "        \n",
    "        # Calculate eigenvectors for the E matrix\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(E_matrix)\n",
    "\n",
    "        # Calculate epsilon terms for each eigenvector\n",
    "        for i in range(N):\n",
    "            ui = eigenvectors[:, i]\n",
    "            # For each day in the Ik segment, project the data onto the eigenvector and square it\n",
    "            epsilon_i_sum = np.sum([(np.dot(ui, historical_data.iloc[t + Ik_length*k])**2) for t in range(Ik_length)])\n",
    "            # Accumulate the results in epsilon\n",
    "            epsilon[i] += epsilon_i_sum.real / Ik_length\n",
    "\n",
    "    # Average epsilon over K segments\n",
    "    epsilon /= number_folds\n",
    "\n",
    "    # Now, we calculate the forecasts using the last set of eigenvectors\n",
    "    cov = pd.DataFrame(index=historical_data.columns, columns=historical_data.columns, data=np.sum([epsilon[i] * np.outer(eigenvectors[:, i], eigenvectors[:, i]) for i in range(N)], axis=0)).fillna(0.)\n",
    "\n",
    "    return cov\n",
    "\n",
    "def portfolio_returns(historical_data, evaluation_window, lookback_window, cov, eta, short_selling=True):\n",
    "\n",
    "    ## we compute the markowitz weights using this forecast\n",
    "\n",
    "    expected_returns = process.noised_array(y=historical_data.iloc[200,:], eta=eta)\n",
    "\n",
    "    if short_selling:\n",
    "\n",
    "        ef = EfficientFrontier(expected_returns=expected_returns, cov_matrix=cov, weight_bounds=(-1, 1))\n",
    "\n",
    "    else:\n",
    "\n",
    "        ef = EfficientFrontier(expected_returns=expected_returns, cov_matrix=cov, weight_bounds=(0, 1))\n",
    "\n",
    "    ef.efficient_return(target_return=expected_returns.mean())\n",
    "\n",
    "    markowitz_weights = ef.clean_weights()\n",
    "\n",
    "    portfolio_returns = pd.DataFrame(index=df_cleaned.iloc[lookback_window[1]:lookback_window[1]+evaluation_window, :].index, columns=['return'], data=np.zeros(len(df_cleaned.iloc[lookback_window[1]:lookback_window[1]+evaluation_window, :].index)))\n",
    "\n",
    "    for ticker, weight in markowitz_weights.items(): \n",
    "\n",
    "    ##  each time we add :            the present value of the return + the weighted \"contribution\" of the stock 'ticker' times is weight in the portfolio\n",
    "        portfolio_returns['return'] = portfolio_returns['return'] + df_cleaned[ticker][lookback_window[1]:lookback_window[1]+evaluation_window]*weight\n",
    "\n",
    "    return portfolio_returns\n",
    "\n",
    "lookback_window = [0, 200]\n",
    "evaluation_window = 1\n",
    "beta = 0.95\n",
    "K = 4  # Number of fold for the cross validation\n",
    "eta = 0.1\n",
    "\n",
    "cov = cov_forecast(beta=beta, lookback_window=lookback_window, number_folds=K, historical_data=df_cleaned)\n",
    "ret = portfolio_returns(historical_data=df_cleaned, evaluation_window=evaluation_window, lookback_window=lookback_window, cov=cov, eta=eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clustering_method' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/test.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/test.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m beta \u001b[39m=\u001b[39m \u001b[39m0.95\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/test.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m K \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m  \u001b[39m# Number of fold for the cross validation\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/khelifanail/Documents/GitHub/Portfolio_clustering_project/Code/test.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m portfolio \u001b[39m=\u001b[39m PyFolioC(number_of_repetitions\u001b[39m=\u001b[39;49mnumber_of_repetitions, historical_data\u001b[39m=\u001b[39;49mhistorical_data, lookback_window\u001b[39m=\u001b[39;49mlookback_window, evaluation_window\u001b[39m=\u001b[39;49mevaluation_window, number_of_clusters\u001b[39m=\u001b[39;49mnumber_of_clusters, sigma\u001b[39m=\u001b[39;49msigma, eta\u001b[39m=\u001b[39;49meta, short_selling\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, cov_method\u001b[39m=\u001b[39;49mcov_method, beta\u001b[39m=\u001b[39;49mbeta, number_folds\u001b[39m=\u001b[39;49mK)\n",
      "File \u001b[0;32m~/Documents/GitHub/Portfolio_clustering_project/Code/PyFolioC.py:681\u001b[0m, in \u001b[0;36mPyFolioC.__init__\u001b[0;34m(self, number_of_repetitions, historical_data, lookback_window, evaluation_window, number_of_clusters, sigma, eta, short_selling, cov_method, beta, number_folds)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, number_of_repetitions, historical_data, lookback_window, evaluation_window, number_of_clusters, sigma, eta, short_selling\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, cov_method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSPONGE\u001b[39m\u001b[39m'\u001b[39m, beta\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, number_folds\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    675\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(historical_data\u001b[39m=\u001b[39mhistorical_data, \n\u001b[1;32m    676\u001b[0m                      lookback_window\u001b[39m=\u001b[39mlookback_window, \n\u001b[1;32m    677\u001b[0m                      evaluation_window\u001b[39m=\u001b[39mevaluation_window, \n\u001b[1;32m    678\u001b[0m                      number_of_clusters\u001b[39m=\u001b[39mnumber_of_clusters, \n\u001b[1;32m    679\u001b[0m                      sigma\u001b[39m=\u001b[39msigma, \n\u001b[1;32m    680\u001b[0m                      eta\u001b[39m=\u001b[39meta, \n\u001b[0;32m--> 681\u001b[0m                      clustering_method\u001b[39m=\u001b[39mclustering_method)\n\u001b[1;32m    683\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumber_of_repetitions \u001b[39m=\u001b[39m number_of_repetitions\n\u001b[1;32m    684\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconsolidated_weight \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconsolidated_W()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clustering_method' is not defined"
     ]
    }
   ],
   "source": [
    "from PyFolioC import PyFolio\n",
    "from PyFolioC import PyFolioC\n",
    "\n",
    "historical_data = df_cleaned\n",
    "number_of_repetitions = 10\n",
    "lookback_window = [0, 50]\n",
    "evaluation_window = 1\n",
    "number_of_clusters = 38\n",
    "cov_method = 'forecast'\n",
    "sigma = 0.1\n",
    "eta = 0.1\n",
    "lookback_window = [0, 200]\n",
    "evaluation_window = 1\n",
    "beta = 0.95\n",
    "K = 4  # Number of fold for the cross validation\n",
    "\n",
    "portfolio = PyFolioC(number_of_repetitions=number_of_repetitions, historical_data=historical_data, lookback_window=lookback_window, evaluation_window=evaluation_window, number_of_clusters=number_of_clusters, sigma=sigma, eta=eta, short_selling=True, cov_method=cov_method, beta=beta, number_folds=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>AA</th>\n",
       "      <th>ABM</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ADI</th>\n",
       "      <th>ADM</th>\n",
       "      <th>ADX</th>\n",
       "      <th>AEE</th>\n",
       "      <th>AEG</th>\n",
       "      <th>AEM</th>\n",
       "      <th>AEP</th>\n",
       "      <th>...</th>\n",
       "      <th>XLI</th>\n",
       "      <th>XLK</th>\n",
       "      <th>XLP</th>\n",
       "      <th>XLU</th>\n",
       "      <th>XLV</th>\n",
       "      <th>XLY</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRX</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>-0.00076</td>\n",
       "      <td>0.00155</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>-0.00571</td>\n",
       "      <td>0.00284</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.00244</td>\n",
       "      <td>0.00439</td>\n",
       "      <td>-0.00032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00187</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>0.00355</td>\n",
       "      <td>0.00116</td>\n",
       "      <td>0.00221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00296</td>\n",
       "      <td>0.00155</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>0.00282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 695 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker       AA      ABM     ABT      ADI      ADM     ADX      AEE      AEG  \\\n",
       "weight -0.00076  0.00155  0.0016 -0.00571  0.00284  0.0008  0.00025  0.00244   \n",
       "\n",
       "ticker      AEM      AEP  ...      XLI      XLK      XLP      XLU      XLV  \\\n",
       "weight  0.00439 -0.00032  ...  0.00187  0.00123  0.00355  0.00116  0.00221   \n",
       "\n",
       "ticker  XLY      XOM      XRX      YUM      ZTR  \n",
       "weight  0.0  0.00296  0.00155  0.00019  0.00282  \n",
       "\n",
       "[1 rows x 695 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio.final_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_W = PyFolioC(number_of_repetitions=number_of_repetitions, historical_data=df_cleaned, lookback_window=lookback_window, evaluation_window=evaluation_window, number_of_clusters=number_of_clusters, sigma=sigma, eta=eta, clustering_method=clustering_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcul_somme(beta):\n",
    "\n",
    "    T = len(consolidated_W.historical_data.columns)\n",
    "    \n",
    "    res = np.zeros((len(df_column[0]), len(df_column[0])))\n",
    "\n",
    "    res = (1 - beta) / (1 - beta**T) * np.sum([(beta**(T-(t+1))) * np.outer(consolidated_W.historical_data[ticker], consolidated_W.historical_data[ticker]) for t, ticker in enumerate(consolidated_W.historical_data.columns)])\n",
    "\n",
    "    return res\n",
    "\n",
    "beta = 0.5\n",
    "\n",
    "res = calcul_somme(beta=beta)\n",
    "res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
